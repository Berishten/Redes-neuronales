# Redes neuronales
- [Red neuronal simple](https://github.com/Berishten/Redes-neuronales/blob/main/Red_neuronal_simple.ipynb)
   Implementaci칩n b치sica de un modelo de regresi칩n lineal, para aproximar a un valor 칰nico utilizando reglas b치sicas
   de c치lculo diferencial, como: derivadas, derivadas parciales.
  
   A groso modo, el modelo funciona de la siguiente manera:
     1. Predicci칩n: la predicci칩n del modelo se define como:
        
        $$\hat{y} = w \cdot x + b$$
     2. C치lculo de gradientes: las gradientes del MSE respecto a los par치metros 洧녻 y 洧녪 son:
        
        $$\frac{\partial \text{MSE}}{\partial w} = 2 \cdot (\hat{y} - y) \cdot x\$$
        
        $$\frac{\partial \text{MSE}}{\partial b} = 2 \cdot (\hat{y} - y)$$
        
     3. Actualizaci칩n de Par치metros: los par치metros se actualizan en cada iteraci칩n usando el descenso de
        gradiente con una tasa de aprendizaje $\alpha$ hasta que el modelo converja en un valor aproximado deseado.

        $$w \leftarrow w - \alpha \cdot \frac{\partial \text{MSE}}{\partial w}$$

        $$b \leftarrow b - \alpha \cdot \frac{\partial \text{MSE}}{\partial b}$$
        
- [RN + ReLU](https://github.com/Berishten/Redes-neuronales/blob/main/RN_%2B_ReLU.ipynb)
   Esta red es muy similar a la anterior pero solo sirve para predecir un valor real positivo, adem치s,
   se incluye el uso de:
   - Funci칩n de activaci칩n ReLU
